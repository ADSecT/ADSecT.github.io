# 附1-组织结构
## 通用教程
**模板：**

- **Temporal-Distributed Backdoor Attack against Video Based Action Recognition.** *AAAI, 2024.*

  ```
  Abstract
  1. Introduction
  2. Related Work
    2.1. Backdoor Attacks and Defenses  # 介绍Backdoor Attack的研究现状+与其他工作的不同之处
    2.2. Video Action Recognition  # 对攻击针对的任务以及对应的模型进行分类，后续要对这几类模型进行攻击
  3. Methodology
    3.1. Threat Model  # 介绍威胁模型（攻击场景/攻击能力/攻击假设等）
    3.2. Backdoor Attacks against Video: A Higher Level of Stealthiness
    3.3. Imperceptible Temporal-Distributed Backdoor Attack against Video Data
  4. Experimental Setup
  5. Limitation and Future Work  # 本工作存在的局限性和后续计划开展的工作
  6. Conclusion
  Acknowledgments
  ```

- **Personalization as a Shortcut for Few-Shot Backdoor Attack against Text-to-Image Diffusion Models.** *AAAI, 2024.*

  ```
  Abstract
  1. Introduction
  2. Related Work
    2.1. Personalization in Text-to-Image Diffusion Models  # 介绍against针对的任务
    2.2. Backdoor Attacks
  3. Preliminary
    3.1. Problem Formulation（介绍一些基础知识）
    3.2. Threat Model（威胁模型）
      3.2.1. Attack scenarios（攻击场景）
      3.2.2. Adversary’s capability（攻击者的能力）
      3.2.3. Adversary’s goal（攻击者的目标）
  4. Method
    4.1. Motivation
    4.2. Backdoor Attack Based on Nouveau-Token Personalization
    4.3. Backdoor Attack Based on Legacy-Token Personalization
  5. Experiments
  6. Discussion
  7. Conclusion
  8. Ethical Impact
  Acknowledgments
  ```

- **COMBAT: Alternated Training for Effective Clean-Label Backdoor Attacks.** *AAAI, 2024.*

  ```
  Abstract
  1. Introduction
  2. Background
    2.1. Threat Model
    2.2. Previous Backdoor Attacks
    2.3. Backdoor Defense Methods
  3. Methodology
    3.1. Problem Overview
    3.2. Trigger Generator
    3.3. Alternated Training
  4. Experiments
  5. Customize the Attack Configurations
  6. Conclusions and Future Works
  Acknowledgments
  ```

- **Chronic Poisoning: Backdoor Attack against Split Learning.** *AAAI, 2024.*

  ```
  Abstract
  1. Introduction
  2. Related Work
  3. Background（背景一般介绍威胁模型和动机）
    3.1. Threat Model
    3.2. Motivation
  4. Apporach
    4.1. Apporach
    4.2. Steal
    4.3. Finetune
    4.4. Implant
  5. Experiments
  6. Summary and Future Work
  Acknowledgments
  ```

- **BadRL: Sparse Targeted Backdoor Attack against Reinforcement Learning.** *AAAI, 2024.*

  ```
  Abstract
  1. Introduction
  2. Related Work
    2.1. Adversarial attack in RL
    2.2. Backdoor attack against RL
  3. Preliminary
  4. Threat Model of Targeted Backdoor Attack
    4.1. Attacker Knowledge（类似攻击场景）
    4.2. Attacker Ability
    4.3. Attack Goal
    4.4. Attack Formulation
  5. BadRL Attack Framework
  6. Attack Feasibility
  7. Experiment
  8. Countermeasure
  9. Conclusion
  Acknowledgments
  ```

  